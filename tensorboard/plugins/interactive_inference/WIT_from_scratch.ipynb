{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What-If Tool from scratch - From CSV to trained model to What-If Tool usage\n",
    "\n",
    "# This notebook shows the process of loading up a dataset from CSV, training a very simple classifier to\n",
    "# predict one of the columns, then using the What-If Tool (WIT) to analyze the training dataset and the trained\n",
    "# model.\n",
    "\n",
    "# It is shown with both the UCI census binary classification task and the UCI iris multiclass classification task.\n",
    "\n",
    "## Setup (install Jupyter, TF, and TF Serving in a virtualenv).\n",
    "# NOTE: Use of a virtualenv, pip installation of tensorflow and docker use for TF Serving aren't the only way\n",
    "# to set all this up. I just find it the simplest to use.\n",
    "\n",
    "# virtualenv tf\n",
    "# source tf/bin/activate\n",
    "# pip install --upgrade pip\n",
    "# pip install jupyter\n",
    "# pip install tensorflow (or tensorflow-gpu)\n",
    "# docker pull tensorflow/serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define helper functions\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import data\n",
    "\n",
    "# Writes a pandas dataframe to disk as a tfrecord file of tf.Example protos,\n",
    "# using only the dataframe columns specified. Non-numeric columns are treated\n",
    "# as strings.\n",
    "def write_df_as_tfrecord(df, filename, columns):\n",
    "    if not os.path.exists(os.path.dirname(filename)):\n",
    "        os.makedirs(os.path.dirname(filename))\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index, row in df.iterrows():\n",
    "        example = tf.train.Example()\n",
    "        for col in columns:\n",
    "            if df[col].dtype is np.dtype(np.int64):\n",
    "                example.features.feature[col].int64_list.value.append(row[col])\n",
    "            elif df[col].dtype is np.dtype(np.float64):\n",
    "                example.features.feature[col].float_list.value.append(row[col])\n",
    "            else:\n",
    "                example.features.feature[col].bytes_list.value.append(row[col].encode('utf-8'))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "# Creates a tf feature spec from the dataframe and columns specified.\n",
    "def create_feature_spec(df, columns):\n",
    "    feature_spec = {}\n",
    "    for f in columns:\n",
    "        if df[f].dtype is np.dtype(np.int64):\n",
    "            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.int64)\n",
    "        elif df[f].dtype is np.dtype(np.float64):\n",
    "            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.float32)\n",
    "        else:\n",
    "            feature_spec[f] = tf.FixedLenFeature(shape=(), dtype=tf.string)\n",
    "    return feature_spec\n",
    "\n",
    "# Parses a serialized tf.Example into input features and target feature from \n",
    "# the provided label feature name and feature spec.\n",
    "def parse_tf_example(example_proto, label, feature_spec):\n",
    "    parsed_features = tf.parse_example(serialized=example_proto, features=feature_spec)\n",
    "    target = parsed_features.pop(label)\n",
    "    return parsed_features, target\n",
    "\n",
    "# An input function for providing input to a model from tf.Examples from tf record files.\n",
    "def tfrecords_input_fn(files_name_pattern, feature_spec, label, mode=tf.estimator.ModeKeys.EVAL,\n",
    "                       num_epochs=None, \n",
    "                       batch_size=64):\n",
    "    shuffle = True if mode == tf.estimator.ModeKeys.TRAIN else False\n",
    "    file_names = tf.matching_files(files_name_pattern)\n",
    "    dataset = data.TFRecordDataset(filenames=file_names)\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=2 * batch_size + 1)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda tf_example: parse_tf_example(tf_example, label, feature_spec))\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    features, target = iterator.get_next()\n",
    "    return features, target\n",
    "\n",
    "# Creates simple numeric and categorical feature columns from a feature spec and a\n",
    "# list of columns from that spec to use.\n",
    "#\n",
    "# NOTE: Models might perform better with some feature engineering such as bucketed\n",
    "# numeric columns and hash-bucket/embedding columns for categorical features.\n",
    "def create_feature_columns(columns, feature_spec):\n",
    "    ret = []\n",
    "    for col in columns:\n",
    "        if feature_spec[col].dtype is tf.int64 or feature_spec[col].dtype is tf.float32:\n",
    "            ret.append(tf.feature_column.numeric_column(col))\n",
    "        else:\n",
    "            ret.append(tf.feature_column.categorical_column_with_vocabulary_list(col, list(df[col].unique())))\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UCI Census - Prepare for model training - This is the only cell that is dataset-specific.\n",
    "\n",
    "tfrecord_path = './data/adult.tfrecord'\n",
    "label_col = 'Target'\n",
    "model_path = './uci_model'\n",
    "n_classes = 2\n",
    "\n",
    "# Read data from CSV to dataframe\n",
    "csv_columns = [\"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital-Status\",\n",
    "               \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital-Gain\", \"Capital-Loss\",\n",
    "               \"Hours-per-week\", \"Country\", \"Target\"]\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "    names=csv_columns,\n",
    "    skipinitialspace=True)\n",
    "\n",
    "# Make the label column numeric (0 and 1), for use in our model\n",
    "df[label_col] = np.where(df[label_col] == '<=50K', 0, 1)\n",
    "\n",
    "# Get list of all columns from the dataset we will use for model input or output.\n",
    "# We will ignore the fnlwgt column in the dataset for training this model.\n",
    "features_and_labels = [f for f in df.columns.values.tolist() if f != 'fnlwgt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iris - Prepare for model training - This is the only cell that is dataset-specific\n",
    "\n",
    "tfrecord_path = './data/iris.tfrecord'\n",
    "label_col = 'class'\n",
    "model_path = './iris_model'\n",
    "n_classes = 3\n",
    "\n",
    "# Read data from CSV to dataframe\n",
    "csv_columns = [\"sepal-length\", \"sepal-width\", \"pedal-length\", \"pedal-width\", \"class-str\"]\n",
    "df = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",\n",
    "    names=csv_columns)\n",
    "\n",
    "# Make the label column numeric for use in our model\n",
    "df[label_col] = np.where(df[\"class-str\"] == 'Iris-setosa', 0, np.where(df[\"class-str\"] == 'Iris-versicolor', 1, 2)).astype(int)\n",
    "\n",
    "# Get list of all columns from the dataset we will use for model input or output.\n",
    "features_and_labels = [f for f in df.columns.values.tolist() if f != 'class-str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create and train the classifier\n",
    "\n",
    "import functools\n",
    "\n",
    "# Write the records to disk as tf.Example protos in tf record file, for use in model training\n",
    "# and later for use by WIT.\n",
    "write_df_as_tfrecord(df, tfrecord_path, features_and_labels)\n",
    "\n",
    "# Create a feature spec for the classifier\n",
    "feature_spec = create_feature_spec(df, features_and_labels)\n",
    "\n",
    "print feature_spec\n",
    "\n",
    "# Create a list of just the input features the classifier will use (removing the label feature)\n",
    "features = [f for f in features_and_labels if f != label_col]\n",
    "\n",
    "# Define and train the classifier\n",
    "train_inpf = functools.partial(tfrecords_input_fn, tfrecord_path, feature_spec, label_col)\n",
    "classifier = tf.estimator.LinearClassifier(feature_columns=create_feature_columns(features, feature_spec),\n",
    "                                           n_classes=n_classes)\n",
    "classifier.train(train_inpf, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the classifier to disk for serving\n",
    "\n",
    "# Uses a parsing serving input receiver function so that it can classify from serialized tf.Examples\n",
    "# using the TensorFlow Serving Classify API.\n",
    "\n",
    "serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\n",
    "classifier.export_savedmodel(model_path, serving_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## What-If Tool usage instructions (serve model, launch TensorBoard, configure What-If Tool)\n",
    "\n",
    "# sudo docker run -p 8500:8500 --mount type=bind,source=[model_path],target=/models/my_model/ -e MODEL_NAME=my_model -t tensorflow/serving\n",
    "# tensorboard --logdir .\n",
    "# Navigate to http://localhost:6006/#whatif&inferenceAddress=localhost%3A8500&modelName=my_model\n",
    "# Set examples path to tfrecord_path and click accept button"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
